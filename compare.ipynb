{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MixedAutoencoder import Mixer, MixedAutoencoder\n",
    "import MixedAutoencoder\n",
    "from DataCleaning import *\n",
    "import DataCleaning\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "seed = 42\n",
    "MixedAutoencoder.setRandom(seed)\n",
    "DataCleaning.setRandom(seed)\n",
    "base_path = \".\"\n",
    "mixer = Mixer(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sets = 4\n",
    "latent_dim = 8\n",
    "model_shape = []\n",
    "base_path = \".\"\n",
    "label = f'demo_{num_sets}_{latent_dim}_[{\"_\".join([str(s) for s in model_shape])}]_compare'\n",
    "demo_size = 15\n",
    "demo_shape = []\n",
    "key_list = [f'set{str(i)}' for i in range(1, num_sets+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{base_path}/data/16PF/data.csv', sep=\"\\t\")\n",
    "data = clean_data(data)\n",
    "column_keys = split_strat(data, num_sets, key_list)\n",
    "column_keys_full = {\"main\": column_keys[\"set1\"]+column_keys[\"set2\"]+column_keys[\"set3\"]}\n",
    "column_keys_extra = {\"set4\": column_keys[\"set4\"]}\n",
    "column_keys_3 = {k:c for k, c in column_keys.items() if k != \"set4\"}\n",
    "key_list_full = list(column_keys_full.keys())\n",
    "key_list_extra = list(column_keys_extra.keys())\n",
    "key_list_3 = list(column_keys_3.keys())\n",
    "\n",
    "data_full = split(data, column_keys_full)\n",
    "data_3 = split(data, column_keys_3)\n",
    "data_extra = split(data, column_keys_extra)\n",
    "train_f, test_f = make_train_test(data_full, 0.8)\n",
    "input_dims_f = get_input_dims(train_f)\n",
    "train_3, test_3 = make_train_test(data_3, 0.8)\n",
    "input_dims_3 = get_input_dims(train_3)\n",
    "train_e, test_e = make_train_test(data_extra, 0.8)\n",
    "input_dims_e = get_input_dims(train_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary accuracy: 0.5032639393471134\n",
      "epoch 0\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 1.3031 - val_loss: 1.1957 - accuracy: 0.2558\n",
      "epoch 1\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 1.1252 - val_loss: 0.9775 - accuracy: 0.3264\n",
      "epoch 2\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 1.0612 - val_loss: 0.9122 - accuracy: 0.3678\n",
      "epoch 3\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 1.0174 - val_loss: 0.8732 - accuracy: 0.3856\n",
      "epoch 4\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.9811 - val_loss: 0.8483 - accuracy: 0.3967\n",
      "epoch 5\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.9504 - val_loss: 0.8315 - accuracy: 0.4028\n",
      "epoch 6\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.9251 - val_loss: 0.8186 - accuracy: 0.4106\n",
      "epoch 7\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.9060 - val_loss: 0.8065 - accuracy: 0.4169\n",
      "epoch 8\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8911 - val_loss: 0.7963 - accuracy: 0.4254\n",
      "epoch 9\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8789 - val_loss: 0.7877 - accuracy: 0.4316\n",
      "epoch 10\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8687 - val_loss: 0.7808 - accuracy: 0.4358\n",
      "epoch 11\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8604 - val_loss: 0.7755 - accuracy: 0.4392\n",
      "epoch 12\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8537 - val_loss: 0.7714 - accuracy: 0.4417\n",
      "epoch 13\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8485 - val_loss: 0.7681 - accuracy: 0.4416\n",
      "epoch 14\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8445 - val_loss: 0.7655 - accuracy: 0.4410\n",
      "epoch 15\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8413 - val_loss: 0.7633 - accuracy: 0.4447\n",
      "epoch 16\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8389 - val_loss: 0.7615 - accuracy: 0.4446\n",
      "epoch 17\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8369 - val_loss: 0.7601 - accuracy: 0.4449\n",
      "epoch 18\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8356 - val_loss: 0.7589 - accuracy: 0.4473\n",
      "epoch 19\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8343 - val_loss: 0.7579 - accuracy: 0.4486\n",
      "epoch 20\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8334 - val_loss: 0.7571 - accuracy: 0.4502\n",
      "epoch 21\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8326 - val_loss: 0.7564 - accuracy: 0.4497\n",
      "epoch 22\n",
      "442/442 [==============================] - 2s 4ms/step - loss: 0.8319 - val_loss: 0.7558 - accuracy: 0.4512\n",
      "epoch 23\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8313 - val_loss: 0.7553 - accuracy: 0.4507\n",
      "epoch 24\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8309 - val_loss: 0.7549 - accuracy: 0.4506\n",
      "Binary accuracy: 0.7922660007824907\n"
     ]
    }
   ],
   "source": [
    "model_shapes = {k: model_shape for k in key_list_3}\n",
    "autoencoder_3 = mixer.make_new(model_shapes, latent_dim, input_dims_3)\n",
    "\n",
    "autoencoder_3.show_total_binary_accuracy(test_3)\n",
    "settings = {\n",
    "    \"training\": [[\"$all\", \"$all\", True, True]]#[[[k1], [k2 for k2 in keys if k1 != k2], True, True] for k1 in keys],\n",
    "    #\"encoder_proximity_training\": [[\"$all\", True]],\n",
    "    #\"plot\": [True, 3, [0, 1, 2]]\n",
    "}\n",
    "autoencoder_3.train_set(train_3, 25, autoencoder_3.make_train_config(settings = settings), batch_size = 64, verbose=True)\n",
    "autoencoder_3.show_total_binary_accuracy(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 1.3726 - val_loss: 1.1958 - accuracy: 0.2899\n",
      "epoch 1\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 1.2202 - val_loss: 1.0620 - accuracy: 0.3390\n",
      "epoch 2\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 1.1520 - val_loss: 0.9998 - accuracy: 0.3746\n",
      "epoch 3\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 1.1073 - val_loss: 0.9571 - accuracy: 0.3875\n",
      "epoch 4\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 1.0726 - val_loss: 0.9252 - accuracy: 0.3939\n",
      "epoch 5\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 1.0441 - val_loss: 0.8999 - accuracy: 0.4103\n",
      "epoch 6\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 1.0152 - val_loss: 0.8737 - accuracy: 0.4174\n",
      "epoch 7\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.9868 - val_loss: 0.8476 - accuracy: 0.4295\n",
      "epoch 8\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.9600 - val_loss: 0.8248 - accuracy: 0.4281\n",
      "epoch 9\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.9368 - val_loss: 0.8058 - accuracy: 0.4323\n",
      "epoch 10\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.9173 - val_loss: 0.7897 - accuracy: 0.4330\n",
      "epoch 11\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.9010 - val_loss: 0.7764 - accuracy: 0.4380\n",
      "epoch 12\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8866 - val_loss: 0.7656 - accuracy: 0.4387\n",
      "epoch 13\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8735 - val_loss: 0.7565 - accuracy: 0.4387\n",
      "epoch 14\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8616 - val_loss: 0.7487 - accuracy: 0.4430\n",
      "epoch 15\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8509 - val_loss: 0.7418 - accuracy: 0.4459\n",
      "epoch 16\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8411 - val_loss: 0.7352 - accuracy: 0.4544\n",
      "epoch 17\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8323 - val_loss: 0.7284 - accuracy: 0.4566\n",
      "epoch 18\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8242 - val_loss: 0.7217 - accuracy: 0.4573\n",
      "epoch 19\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8168 - val_loss: 0.7152 - accuracy: 0.4615\n",
      "epoch 20\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8098 - val_loss: 0.7092 - accuracy: 0.4630\n",
      "epoch 21\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8032 - val_loss: 0.7037 - accuracy: 0.4672\n",
      "epoch 22\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7969 - val_loss: 0.6986 - accuracy: 0.4701\n",
      "epoch 23\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7909 - val_loss: 0.6942 - accuracy: 0.4672\n",
      "epoch 24\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7852 - val_loss: 0.6901 - accuracy: 0.4694\n"
     ]
    }
   ],
   "source": [
    "model_shapes = {k: model_shape for k in key_list_full}\n",
    "autoencoder_f = mixer.make_new(model_shapes, latent_dim, input_dims_f)\n",
    "\n",
    "\n",
    "settings = {\n",
    "    \"training\": [[\"$all\", \"$all\", True, True]]#[[[k1], [k2 for k2 in keys if k1 != k2], True, True] for k1 in keys],\n",
    "    #\"encoder_proximity_training\": [[\"$all\", True]],\n",
    "    #\"plot\": [True, 3, [0, 1, 2]]\n",
    "}\n",
    "autoencoder_f.train_set(train_f, 25, autoencoder_f.make_train_config(settings = settings), batch_size = 64, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "442/442 [==============================] - 2s 4ms/step - loss: 1.2675 - val_loss: 1.4107 - accuracy: 0.2864\n",
      "epoch 1\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 1.0762 - val_loss: 1.2370 - accuracy: 0.3207\n",
      "epoch 2\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.9518 - val_loss: 1.1168 - accuracy: 0.3539\n",
      "epoch 3\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8835 - val_loss: 1.0441 - accuracy: 0.3747\n",
      "epoch 4\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8510 - val_loss: 1.0041 - accuracy: 0.3833\n",
      "epoch 5\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8358 - val_loss: 0.9844 - accuracy: 0.3853\n",
      "epoch 6\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8285 - val_loss: 0.9749 - accuracy: 0.3879\n",
      "epoch 7\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8250 - val_loss: 0.9698 - accuracy: 0.3881\n",
      "epoch 8\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8232 - val_loss: 0.9668 - accuracy: 0.3898\n",
      "epoch 9\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8223 - val_loss: 0.9649 - accuracy: 0.3882\n",
      "epoch 10\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8219 - val_loss: 0.9636 - accuracy: 0.3875\n",
      "epoch 11\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8217 - val_loss: 0.9628 - accuracy: 0.3869\n",
      "epoch 12\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8217 - val_loss: 0.9622 - accuracy: 0.3882\n",
      "epoch 13\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8217 - val_loss: 0.9618 - accuracy: 0.3895\n",
      "epoch 14\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8217 - val_loss: 0.9615 - accuracy: 0.3900\n",
      "epoch 15\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8218 - val_loss: 0.9613 - accuracy: 0.3882\n",
      "epoch 16\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8218 - val_loss: 0.9612 - accuracy: 0.3882\n",
      "epoch 17\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8219 - val_loss: 0.9610 - accuracy: 0.3891\n",
      "epoch 18\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8219 - val_loss: 0.9609 - accuracy: 0.3882\n",
      "epoch 19\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8219 - val_loss: 0.9609 - accuracy: 0.3887\n",
      "epoch 20\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8220 - val_loss: 0.9608 - accuracy: 0.3878\n",
      "epoch 21\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8220 - val_loss: 0.9608 - accuracy: 0.3878\n",
      "epoch 22\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8220 - val_loss: 0.9607 - accuracy: 0.3878\n",
      "epoch 23\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8220 - val_loss: 0.9607 - accuracy: 0.3878\n",
      "epoch 24\n",
      "442/442 [==============================] - 2s 3ms/step - loss: 0.8220 - val_loss: 0.9607 - accuracy: 0.3884\n",
      "Encoder binary accuracy: 0.7923534770427518\n",
      "Decoder binary accuracy: 0.7953541040349745\n"
     ]
    }
   ],
   "source": [
    "model_shapes = {k: model_shape for k in key_list_extra}\n",
    "autoencoder_3 = mixer.add_new(autoencoder_3, model_shapes, input_dims_e)\n",
    "\n",
    "settings = {\n",
    "    \"training\": [[key_list_extra, \"$all\", True, False], [\"$all\", key_list_extra, False, True]]#[[[k1], [k2 for k2 in keys if k1 != k2], True, True] for k1 in keys],\n",
    "    #\"encoder_proximity_training\": [[\"$all\", True]],\n",
    "    #\"plot\": [True, 3, [0, 1, 2]]\n",
    "}\n",
    "autoencoder_3.train_set(train_3|train_e, 25, autoencoder_3.make_train_config(settings = settings), batch_size = 64, verbose=True)\n",
    "autoencoder_3.show_binary_accuracy(key_list_extra, train_3|train_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 1.4170 - val_loss: 1.4630 - accuracy: 0.2622\n",
      "epoch 1\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 1.2215 - val_loss: 1.2761 - accuracy: 0.3008\n",
      "epoch 2\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 1.1017 - val_loss: 1.1659 - accuracy: 0.3222\n",
      "epoch 3\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 1.0210 - val_loss: 1.0903 - accuracy: 0.3498\n",
      "epoch 4\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.9634 - val_loss: 1.0372 - accuracy: 0.3665\n",
      "epoch 5\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.9220 - val_loss: 0.9975 - accuracy: 0.3751\n",
      "epoch 6\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8906 - val_loss: 0.9668 - accuracy: 0.3914\n",
      "epoch 7\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8661 - val_loss: 0.9426 - accuracy: 0.3991\n",
      "epoch 8\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8468 - val_loss: 0.9236 - accuracy: 0.4006\n",
      "epoch 9\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8323 - val_loss: 0.9087 - accuracy: 0.4101\n",
      "epoch 10\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8215 - val_loss: 0.8971 - accuracy: 0.4070\n",
      "epoch 11\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8136 - val_loss: 0.8879 - accuracy: 0.4099\n",
      "epoch 12\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8078 - val_loss: 0.8805 - accuracy: 0.4165\n",
      "epoch 13\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.8032 - val_loss: 0.8745 - accuracy: 0.4177\n",
      "epoch 14\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7997 - val_loss: 0.8695 - accuracy: 0.4180\n",
      "epoch 15\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7969 - val_loss: 0.8653 - accuracy: 0.4119\n",
      "epoch 16\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7947 - val_loss: 0.8620 - accuracy: 0.4166\n",
      "epoch 17\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7930 - val_loss: 0.8593 - accuracy: 0.4181\n",
      "epoch 18\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7915 - val_loss: 0.8572 - accuracy: 0.4175\n",
      "epoch 19\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7904 - val_loss: 0.8555 - accuracy: 0.4148\n",
      "epoch 20\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7895 - val_loss: 0.8543 - accuracy: 0.4139\n",
      "epoch 21\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7888 - val_loss: 0.8533 - accuracy: 0.4145\n",
      "epoch 22\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7882 - val_loss: 0.8525 - accuracy: 0.4112\n",
      "epoch 23\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7877 - val_loss: 0.8520 - accuracy: 0.4096\n",
      "epoch 24\n",
      "442/442 [==============================] - 1s 2ms/step - loss: 0.7873 - val_loss: 0.8515 - accuracy: 0.4120\n",
      "Encoder binary accuracy: 0.7869232450270959\n",
      "Decoder binary accuracy: 0.7999765531199847\n"
     ]
    }
   ],
   "source": [
    "model_shapes = {k: model_shape for k in key_list_extra}\n",
    "autoencoder_f = mixer.add_new(autoencoder_f, model_shapes, input_dims_e)\n",
    "\n",
    "settings = {\n",
    "    \"training\": [[key_list_extra, \"$all\", True, False], [\"$all\", key_list_extra, False, True]]#[[[k1], [k2 for k2 in keys if k1 != k2], True, True] for k1 in keys],\n",
    "    #\"encoder_proximity_training\": [[\"$all\", True]],\n",
    "    #\"plot\": [True, 3, [0, 1, 2]]\n",
    "}\n",
    "autoencoder_f.train_set(train_f|train_e, 25, autoencoder_f.make_train_config(settings = settings), batch_size = 64, verbose=True)\n",
    "autoencoder_f.show_binary_accuracy(key_list_extra, train_f|train_e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encoderVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
