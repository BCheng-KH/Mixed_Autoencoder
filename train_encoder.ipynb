{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MixedAutoencoder import Mixer, MixedAutoencoder\n",
    "import MixedAutoencoder\n",
    "from DataCleaning import *\n",
    "import DataCleaning\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "seed = 42\n",
    "MixedAutoencoder.setRandom(seed)\n",
    "DataCleaning.setRandom(seed)\n",
    "base_path = \".\"\n",
    "mixer = Mixer(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_sets = 4\n",
    "latent_dim = 7\n",
    "model_shape = []\n",
    "base_path = \".\"\n",
    "label = f'demo_{num_sets}_{latent_dim}_[{\"_\".join([str(s) for s in model_shape])}]'\n",
    "demo_size = 15\n",
    "demo_shape = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_key_list = [f'set{str(i)}' for i in range(1, num_sets+1)]\n",
    "demo_key_list = ['demo']\n",
    "data = pd.read_csv(f'{base_path}/data/16PF/data.csv', sep=\"\\t\")\n",
    "data = clean_data(data)\n",
    "data = data.sample(frac=1)\n",
    "demo_column_keys = {demo_key_list[0]: split_n_strat(data, demo_size)}\n",
    "\n",
    "base_column_keys = split_strat([k for k in list(data) if k not in demo_column_keys[demo_key_list[0]]],num_sets, base_key_list)\n",
    "split_data = split(data, base_column_keys)\n",
    "train, test = make_train_test(split_data, 0.8)\n",
    "input_dims = get_input_dims(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary accuracy: 0.5083089518449392\n",
      "epoch 0\n",
      "442/442 [==============================] - 5s 9ms/step - loss: 1.1875 - val_loss: 1.2687 - accuracy: 0.2728\n",
      "epoch 1\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 1.0747 - val_loss: 1.1839 - accuracy: 0.3091\n",
      "epoch 2\n",
      "442/442 [==============================] - 4s 5ms/step - loss: 0.9805 - val_loss: 1.1015 - accuracy: 0.3318\n",
      "epoch 3\n",
      "442/442 [==============================] - 4s 5ms/step - loss: 0.9296 - val_loss: 1.0554 - accuracy: 0.3491\n",
      "epoch 4\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8998 - val_loss: 1.0259 - accuracy: 0.3680\n",
      "epoch 5\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8776 - val_loss: 0.9971 - accuracy: 0.3817\n",
      "epoch 6\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8622 - val_loss: 0.9801 - accuracy: 0.3898\n",
      "epoch 7\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8518 - val_loss: 0.9713 - accuracy: 0.3941\n",
      "epoch 8\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8443 - val_loss: 0.9640 - accuracy: 0.3953\n",
      "epoch 9\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8384 - val_loss: 0.9568 - accuracy: 0.3966\n",
      "epoch 10\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8336 - val_loss: 0.9498 - accuracy: 0.3970\n",
      "epoch 11\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8298 - val_loss: 0.9430 - accuracy: 0.3994\n",
      "epoch 12\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8267 - val_loss: 0.9364 - accuracy: 0.4013\n",
      "epoch 13\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8242 - val_loss: 0.9303 - accuracy: 0.4038\n",
      "epoch 14\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8220 - val_loss: 0.9249 - accuracy: 0.4055\n",
      "epoch 15\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8203 - val_loss: 0.9201 - accuracy: 0.4075\n",
      "epoch 16\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8187 - val_loss: 0.9160 - accuracy: 0.4072\n",
      "epoch 17\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8173 - val_loss: 0.9124 - accuracy: 0.4074\n",
      "epoch 18\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8160 - val_loss: 0.9094 - accuracy: 0.4095\n",
      "epoch 19\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8148 - val_loss: 0.9068 - accuracy: 0.4102\n",
      "epoch 20\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8137 - val_loss: 0.9046 - accuracy: 0.4095\n",
      "epoch 21\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8128 - val_loss: 0.9027 - accuracy: 0.4100\n",
      "epoch 22\n",
      "442/442 [==============================] - 4s 5ms/step - loss: 0.8118 - val_loss: 0.9010 - accuracy: 0.4100\n",
      "epoch 23\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8110 - val_loss: 0.8996 - accuracy: 0.4111\n",
      "epoch 24\n",
      "442/442 [==============================] - 4s 5ms/step - loss: 0.8103 - val_loss: 0.8983 - accuracy: 0.4113\n",
      "Binary accuracy: 0.7885958647489492\n"
     ]
    }
   ],
   "source": [
    "model_shapes = {k: model_shape for k in base_key_list}\n",
    "autoencoder_set = mixer.make_new(model_shapes, latent_dim, input_dims)\n",
    "autoencoder_set.show_total_binary_accuracy(test)\n",
    "settings = {\n",
    "    \"training\": [[\"$all\", \"$all\", True, True]]#[[[k1], [k2 for k2 in keys if k1 != k2], True, True] for k1 in keys],\n",
    "    #\"encoder_proximity_training\": [[\"$all\", True]],\n",
    "    #\"plot\": [True, 3, [0, 1, 2]]\n",
    "}\n",
    "autoencoder_set.train_set(train, 25, autoencoder_set.make_train_config(settings = settings), batch_size = 64, verbose=True)\n",
    "autoencoder_set.show_total_binary_accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "442/442 [==============================] - 3s 6ms/step - loss: 1.4392 - val_loss: 1.4735 - accuracy: 0.2871\n",
      "epoch 1\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 1.1562 - val_loss: 1.2036 - accuracy: 0.3149\n",
      "epoch 2\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 1.0057 - val_loss: 1.0546 - accuracy: 0.3420\n",
      "epoch 3\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.9315 - val_loss: 0.9792 - accuracy: 0.3654\n",
      "epoch 4\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8913 - val_loss: 0.9398 - accuracy: 0.3873\n",
      "epoch 5\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8702 - val_loss: 0.9217 - accuracy: 0.3938\n",
      "epoch 6\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8597 - val_loss: 0.9143 - accuracy: 0.3927\n",
      "epoch 7\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8545 - val_loss: 0.9113 - accuracy: 0.3943\n",
      "epoch 8\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8520 - val_loss: 0.9102 - accuracy: 0.3986\n",
      "epoch 9\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8508 - val_loss: 0.9098 - accuracy: 0.4034\n",
      "epoch 10\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8503 - val_loss: 0.9097 - accuracy: 0.4091\n",
      "epoch 11\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8500 - val_loss: 0.9096 - accuracy: 0.4096\n",
      "epoch 12\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8499 - val_loss: 0.9095 - accuracy: 0.4092\n",
      "epoch 13\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8499 - val_loss: 0.9094 - accuracy: 0.4097\n",
      "epoch 14\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8498 - val_loss: 0.9093 - accuracy: 0.4088\n",
      "epoch 15\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8498 - val_loss: 0.9092 - accuracy: 0.4086\n",
      "epoch 16\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8499 - val_loss: 0.9091 - accuracy: 0.4086\n",
      "epoch 17\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8499 - val_loss: 0.9091 - accuracy: 0.4086\n",
      "epoch 18\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8499 - val_loss: 0.9090 - accuracy: 0.4074\n",
      "epoch 19\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8499 - val_loss: 0.9090 - accuracy: 0.4076\n",
      "epoch 20\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8500 - val_loss: 0.9089 - accuracy: 0.4074\n",
      "epoch 21\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8499 - val_loss: 0.9089 - accuracy: 0.4076\n",
      "epoch 22\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8500 - val_loss: 0.9088 - accuracy: 0.4074\n",
      "epoch 23\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8500 - val_loss: 0.9088 - accuracy: 0.4079\n",
      "epoch 24\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8500 - val_loss: 0.9088 - accuracy: 0.4077\n",
      "Encoder binary accuracy: 0.769688130325802\n",
      "Decoder binary accuracy: 0.8243201229527429\n"
     ]
    }
   ],
   "source": [
    "demo_split_data = split(data, demo_column_keys)\n",
    "dtrain, dtest = make_train_test(demo_split_data, 0.8)\n",
    "demo_input_dims = get_input_dims(dtrain)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "demo_shapes = {k: demo_shape for k in demo_key_list}\n",
    "autoencoder_set = mixer.add_new(autoencoder_set, demo_shapes, demo_input_dims)\n",
    "\n",
    "settings = {\n",
    "    \"training\": [[demo_key_list, \"$all\", True, False], [\"$all\", demo_key_list, False, True]]#[[[k1], [k2 for k2 in keys if k1 != k2], True, True] for k1 in keys],\n",
    "    #\"encoder_proximity_training\": [[\"$all\", True]],\n",
    "    #\"plot\": [True, 3, [0, 1, 2]]\n",
    "}\n",
    "autoencoder_set.train_set(train | dtrain, 25, autoencoder_set.make_train_config(settings = settings), batch_size = 64, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder binary accuracy: 0.769688130325802\n",
      "Decoder binary accuracy: 0.8243201229527429\n"
     ]
    }
   ],
   "source": [
    "autoencoder_set.show_binary_accuracy(demo_key_list, test | dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_7_[]/encoder_set1\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_7_[]/decoder_set1\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_7_[]/encoder_set2\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_7_[]/decoder_set2\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_7_[]/encoder_set3\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_7_[]/decoder_set3\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_7_[]/encoder_set4\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_7_[]/decoder_set4\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_7_[]/encoder_demo\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_7_[]/decoder_demo\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mixer.save_to_label(autoencoder_set, extra = {\"columns\" : base_column_keys|demo_column_keys}, label = label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encoderVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
