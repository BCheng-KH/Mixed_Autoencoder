{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MixedAutoencoder import Mixer, MixedAutoencoder\n",
    "import MixedAutoencoder\n",
    "from DataCleaning import *\n",
    "import DataCleaning\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "seed = 42\n",
    "MixedAutoencoder.setRandom(seed)\n",
    "DataCleaning.setRandom(seed)\n",
    "base_path = \".\"\n",
    "mixer = Mixer(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_sets = 4\n",
    "latent_dim = 8\n",
    "model_shape = []\n",
    "base_path = \".\"\n",
    "label = f'demo_{num_sets}_{latent_dim}_[{\"_\".join([str(s) for s in model_shape])}]'\n",
    "demo_size = 15\n",
    "demo_shape = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_key_list = [f'set{str(i)}' for i in range(1, num_sets+1)]\n",
    "demo_key_list = ['demo']\n",
    "data = pd.read_csv(f'{base_path}/data/16PF/data.csv', sep=\"\\t\")\n",
    "data = clean_data(data)\n",
    "data = data.sample(frac=1)\n",
    "demo_column_keys = {demo_key_list[0]: split_n_strat(data, demo_size)}\n",
    "\n",
    "base_column_keys = split_strat([k for k in list(data) if k not in demo_column_keys[demo_key_list[0]]],num_sets, base_key_list)\n",
    "split_data = split(data, base_column_keys)\n",
    "train, test = make_train_test(split_data, 0.8)\n",
    "input_dims = get_input_dims(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary accuracy: 0.49523964861434355\n",
      "epoch 0\n",
      "442/442 [==============================] - 6s 11ms/step - loss: 1.2121 - val_loss: 1.1430 - accuracy: 0.3015\n",
      "epoch 1\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 1.0394 - val_loss: 0.9640 - accuracy: 0.3762\n",
      "epoch 2\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.9759 - val_loss: 0.8815 - accuracy: 0.4049\n",
      "epoch 3\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.9396 - val_loss: 0.8163 - accuracy: 0.4209\n",
      "epoch 4\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.9163 - val_loss: 0.7801 - accuracy: 0.4358\n",
      "epoch 5\n",
      "442/442 [==============================] - 5s 7ms/step - loss: 0.8985 - val_loss: 0.7601 - accuracy: 0.4440\n",
      "epoch 6\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8839 - val_loss: 0.7495 - accuracy: 0.4510\n",
      "epoch 7\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8727 - val_loss: 0.7431 - accuracy: 0.4541\n",
      "epoch 8\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8646 - val_loss: 0.7388 - accuracy: 0.4589\n",
      "epoch 9\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8586 - val_loss: 0.7356 - accuracy: 0.4623\n",
      "epoch 10\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8541 - val_loss: 0.7326 - accuracy: 0.4639\n",
      "epoch 11\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8504 - val_loss: 0.7298 - accuracy: 0.4637\n",
      "epoch 12\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8475 - val_loss: 0.7273 - accuracy: 0.4645\n",
      "epoch 13\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8449 - val_loss: 0.7250 - accuracy: 0.4668\n",
      "epoch 14\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8426 - val_loss: 0.7230 - accuracy: 0.4690\n",
      "epoch 15\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8407 - val_loss: 0.7212 - accuracy: 0.4705\n",
      "epoch 16\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8388 - val_loss: 0.7196 - accuracy: 0.4697\n",
      "epoch 17\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8370 - val_loss: 0.7182 - accuracy: 0.4695\n",
      "epoch 18\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8353 - val_loss: 0.7171 - accuracy: 0.4713\n",
      "epoch 19\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8337 - val_loss: 0.7159 - accuracy: 0.4718\n",
      "epoch 20\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8323 - val_loss: 0.7150 - accuracy: 0.4743\n",
      "epoch 21\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8310 - val_loss: 0.7141 - accuracy: 0.4732\n",
      "epoch 22\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8296 - val_loss: 0.7134 - accuracy: 0.4747\n",
      "epoch 23\n",
      "442/442 [==============================] - 4s 6ms/step - loss: 0.8285 - val_loss: 0.7128 - accuracy: 0.4743\n",
      "epoch 24\n",
      "442/442 [==============================] - 5s 6ms/step - loss: 0.8276 - val_loss: 0.7122 - accuracy: 0.4749\n",
      "Binary accuracy: 0.7908117794910721\n"
     ]
    }
   ],
   "source": [
    "model_shapes = {k: model_shape for k in base_key_list}\n",
    "autoencoder_set = mixer.make_new(model_shapes, latent_dim, input_dims)\n",
    "\n",
    "autoencoder_set.show_total_binary_accuracy(test)\n",
    "settings = {\n",
    "    \"training\": [[\"$all\", \"$all\", True, True]]#[[[k1], [k2 for k2 in keys if k1 != k2], True, True] for k1 in keys],\n",
    "    #\"encoder_proximity_training\": [[\"$all\", True]],\n",
    "    #\"plot\": [True, 3, [0, 1, 2]]\n",
    "}\n",
    "autoencoder_set.train_set(train, 25, autoencoder_set.make_train_config(settings = settings), batch_size = 64, verbose=True)\n",
    "autoencoder_set.show_total_binary_accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary accuracy: 0.7628171912149404\n"
     ]
    }
   ],
   "source": [
    "model_shapes_3d = {k: [8] for k in base_key_list}\n",
    "autoencoder_set_3d = mixer.make_new(model_shapes_3d, 3, input_dims)\n",
    "autoencoder_set_3d.train_set(train, 25, autoencoder_set_3d.make_train_config(settings = settings), batch_size = 64, verbose=False)\n",
    "autoencoder_set_3d.show_total_binary_accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "442/442 [==============================] - 3s 7ms/step - loss: 1.3415 - val_loss: 1.4457 - accuracy: 0.2966\n",
      "epoch 1\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 1.0806 - val_loss: 1.1645 - accuracy: 0.3495\n",
      "epoch 2\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.9363 - val_loss: 0.9831 - accuracy: 0.3990\n",
      "epoch 3\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8677 - val_loss: 0.9062 - accuracy: 0.4220\n",
      "epoch 4\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8386 - val_loss: 0.8748 - accuracy: 0.4361\n",
      "epoch 5\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8258 - val_loss: 0.8614 - accuracy: 0.4341\n",
      "epoch 6\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8193 - val_loss: 0.8541 - accuracy: 0.4348\n",
      "epoch 7\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8157 - val_loss: 0.8495 - accuracy: 0.4348\n",
      "epoch 8\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8136 - val_loss: 0.8465 - accuracy: 0.4350\n",
      "epoch 9\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8123 - val_loss: 0.8445 - accuracy: 0.4372\n",
      "epoch 10\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8114 - val_loss: 0.8431 - accuracy: 0.4377\n",
      "epoch 11\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8108 - val_loss: 0.8422 - accuracy: 0.4370\n",
      "epoch 12\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8104 - val_loss: 0.8415 - accuracy: 0.4387\n",
      "epoch 13\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8101 - val_loss: 0.8410 - accuracy: 0.4377\n",
      "epoch 14\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8099 - val_loss: 0.8407 - accuracy: 0.4359\n",
      "epoch 15\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8098 - val_loss: 0.8405 - accuracy: 0.4360\n",
      "epoch 16\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8097 - val_loss: 0.8403 - accuracy: 0.4359\n",
      "epoch 17\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8096 - val_loss: 0.8402 - accuracy: 0.4360\n",
      "epoch 18\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8095 - val_loss: 0.8401 - accuracy: 0.4364\n",
      "epoch 19\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8095 - val_loss: 0.8401 - accuracy: 0.4359\n",
      "epoch 20\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8094 - val_loss: 0.8400 - accuracy: 0.4362\n",
      "epoch 21\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8094 - val_loss: 0.8400 - accuracy: 0.4367\n",
      "epoch 22\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8094 - val_loss: 0.8400 - accuracy: 0.4367\n",
      "epoch 23\n",
      "442/442 [==============================] - 3s 5ms/step - loss: 0.8093 - val_loss: 0.8400 - accuracy: 0.4367\n",
      "epoch 24\n",
      "442/442 [==============================] - 3s 4ms/step - loss: 0.8094 - val_loss: 0.8400 - accuracy: 0.4365\n"
     ]
    }
   ],
   "source": [
    "demo_split_data = split(data, demo_column_keys)\n",
    "dtrain, dtest = make_train_test(demo_split_data, 0.8)\n",
    "demo_input_dims = get_input_dims(dtrain)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "demo_shapes = {k: demo_shape for k in demo_key_list}\n",
    "autoencoder_set = mixer.add_new(autoencoder_set, demo_shapes, demo_input_dims)\n",
    "\n",
    "settings = {\n",
    "    \"training\": [[demo_key_list, \"$all\", True, False], [\"$all\", demo_key_list, False, True]]#[[[k1], [k2 for k2 in keys if k1 != k2], True, True] for k1 in keys],\n",
    "    #\"encoder_proximity_training\": [[\"$all\", True]],\n",
    "    #\"plot\": [True, 3, [0, 1, 2]]\n",
    "}\n",
    "autoencoder_set.train_set(train | dtrain, 25, autoencoder_set.make_train_config(settings = settings), batch_size = 64, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder binary accuracy: 0.7538527166310137\n",
      "Decoder binary accuracy: 0.7975246306861448\n"
     ]
    }
   ],
   "source": [
    "demo_shapes_3d = {k: [8] for k in demo_key_list}\n",
    "autoencoder_set_3d = mixer.add_new(autoencoder_set_3d, demo_shapes_3d, demo_input_dims)\n",
    "autoencoder_set_3d.train_set(train | dtrain, 25, autoencoder_set_3d.make_train_config(settings = settings), batch_size = 64, verbose=False)\n",
    "autoencoder_set_3d.show_binary_accuracy(demo_key_list, test | dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder binary accuracy: 0.7717992308995214\n",
      "Decoder binary accuracy: 0.8264166305455654\n"
     ]
    }
   ],
   "source": [
    "autoencoder_set.show_binary_accuracy(demo_key_list, test | dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]/encoder_set1\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]/decoder_set1\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]/encoder_set2\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]/decoder_set2\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]/encoder_set3\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]/decoder_set3\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]/encoder_set4\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]/decoder_set4\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]/encoder_demo\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]/decoder_demo\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mixer.save_to_label(autoencoder_set, extra = {\"columns\" : base_column_keys|demo_column_keys}, label = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]_3d/encoder_set1\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]_3d/decoder_set1\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]_3d/encoder_set2\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]_3d/decoder_set2\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]_3d/encoder_set3\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]_3d/decoder_set3\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]_3d/encoder_set4\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]_3d/decoder_set4\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]_3d/encoder_demo\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./Models/model_demo_4_8_[]_3d/decoder_demo\\assets\n"
     ]
    }
   ],
   "source": [
    "mixer.save_to_label(autoencoder_set_3d, extra = {\"columns\" : base_column_keys|demo_column_keys}, label = label+\"_3d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encoderVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
